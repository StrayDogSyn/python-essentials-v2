{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e40feca",
   "metadata": {},
   "source": [
    "# ğŸ§¹ Week 5 â€” Group Session: Data Cleaning Challenge\n",
    "\n",
    "## ğŸ¤ Collaborative Data Cleaning\n",
    "\n",
    "Welcome to the **group session** for Data Cleaning! Today you'll work as a team to clean a messy real-world dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ­ Team Roles (Rotate Each Activity!)\n",
    "\n",
    "| Role | Responsibility | Focus Area |\n",
    "|------|---------------|------------|\n",
    "| ğŸ” **Data Detective** | Find and document data issues | Missing values, outliers |\n",
    "| ğŸ§¹ **Cleaner** | Write cleaning code | String cleaning, type conversion |\n",
    "| âœ… **Validator** | Check data quality after cleaning | Validation rules |\n",
    "| ğŸ“Š **Presenter** | Explain approach to class | Documentation |\n",
    "\n",
    "### â° Session Timeline\n",
    "\n",
    "| Time | Activity |\n",
    "|------|----------|\n",
    "| 0-5 min | Setup & Role Assignment |\n",
    "| 5-20 min | Activity 1: Data Quality Audit |\n",
    "| 20-40 min | Activity 2: Collaborative Cleaning |\n",
    "| 40-55 min | Activity 3: Validation Challenge |\n",
    "| 55-60 min | Share & Discuss |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4979c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸš€ SETUP: Run this cell first!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… Setup Complete!\")\n",
    "print(\"ğŸ­ Assign your team roles before starting!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba02394",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š The Challenge Dataset: E-Commerce Orders\n",
    "\n",
    "Your team has been given a messy dataset of e-commerce orders. Your mission: **clean it and validate it!**\n",
    "\n",
    "### ğŸ“‹ Dataset Overview\n",
    "- Customer orders from an online store\n",
    "- Contains: customer info, order details, product data\n",
    "- **WARNING:** This data has MANY issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š CREATE THE MESSY DATASET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# This simulates real-world messy data you might encounter\n",
    "\n",
    "messy_orders = pd.DataFrame({\n",
    "    'order_id': [1001, 1002, 1003, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012],\n",
    "    'customer_name': ['  John Smith', 'MARY JONES', 'bob wilson', None, 'Alice Brown', \n",
    "                      'john smith', 'Sarah Lee', 'Mike  Davis', 'Emma White', 'TOM GREEN',\n",
    "                      'Lisa Black', 'None', 'Chris Hall'],\n",
    "    'email': ['john@email.com', 'mary@email', 'bob@email.com', 'duplicate@test.com',\n",
    "              'alice@company.org', 'john@email.com', '', 'mike@email.com', 'invalid-email',\n",
    "              'tom@email.com', 'lisa@email.com', 'fake', 'chris@email.com'],\n",
    "    'phone': ['555-1234', '5551234', '(555) 123-4567', '555.123.4567', None,\n",
    "              '555-1234', 'call me', '555-9999', '555-8888', '555-7777',\n",
    "              '555-6666', '555-5555', 'N/A'],\n",
    "    'order_date': ['2024-01-15', '01/20/2024', '2024-02-01', '2024-02-01', 'invalid',\n",
    "                   '2024-03-10', '2024/03/15', '2024-04-01', '04-05-2024', '2024-04-20',\n",
    "                   '2024-05-01', '2024-05-15', 'TBD'],\n",
    "    'product': ['Widget', 'widget', 'GADGET', 'Gadget', 'Gizmo', \n",
    "                'Widget', 'Doohickey', 'Thingamajig', 'widget', 'GIZMO',\n",
    "                'Gadget', 'Widget', 'doohickey'],\n",
    "    'quantity': [2, 1, 3, 3, -1, 0, 5, 1, 'two', 2, 1, 100000, 3],\n",
    "    'unit_price': ['29.99', '49.99', '19.99', '19.99', '39.99', \n",
    "                   'free', '15.99', '25.99', '29.99', '39.99',\n",
    "                   '49.99', '-10.00', '15.99'],\n",
    "    'status': ['Shipped', 'DELIVERED', 'pending', 'Pending', 'Cancelled',\n",
    "               'shipped', None, 'Processing', 'delivered', 'SHIPPED',\n",
    "               'Pending', 'Unknown', 'processing']\n",
    "})\n",
    "\n",
    "print(\"ğŸ“Š MESSY E-COMMERCE ORDERS DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(messy_orders)\n",
    "print(f\"\\nğŸ“ Shape: {messy_orders.shape}\")\n",
    "print(f\"ğŸ“‹ Columns: {list(messy_orders.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b3aef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” Activity 1: Data Quality Audit (15 min)\n",
    "\n",
    "**ğŸ” Data Detective:** Lead this activity! Find ALL the data quality issues.\n",
    "\n",
    "### ğŸ“‹ Audit Checklist\n",
    "Work together to identify issues in each category:\n",
    "\n",
    "1. **Missing Values** - Which columns have NULL/None/empty values?\n",
    "2. **Duplicates** - Are there duplicate orders?\n",
    "3. **Format Issues** - Inconsistent formatting (case, spacing, date formats)?\n",
    "4. **Invalid Values** - Negative quantities? Impossible prices? Bad emails?\n",
    "5. **Type Problems** - Numbers stored as text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ” ACTIVITY 1: DATA QUALITY AUDIT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Work together to find all the issues!\n",
    "\n",
    "df = messy_orders.copy()\n",
    "\n",
    "print(\"ğŸ” DATA QUALITY AUDIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CHECK 1: Missing Values\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n1ï¸âƒ£ MISSING VALUES:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CHECK 2: Duplicates\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n2ï¸âƒ£ DUPLICATE ORDER IDs:\")\n",
    "dup_ids = df[df.duplicated(subset=['order_id'], keep=False)]\n",
    "print(dup_ids[['order_id', 'customer_name', 'product']])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CHECK 3: Data Types\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n3ï¸âƒ£ DATA TYPES:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CHECK 4: Unique Values (to spot inconsistencies)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n4ï¸âƒ£ UNIQUE PRODUCTS (notice case inconsistencies):\")\n",
    "print(df['product'].unique())\n",
    "\n",
    "print(\"\\n5ï¸âƒ£ UNIQUE STATUSES:\")\n",
    "print(df['status'].unique())\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TEAM DISCUSSION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ TEAM DISCUSSION: List ALL issues you found!\")\n",
    "print(\"   Use the cell below to document your findings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c162c01",
   "metadata": {},
   "source": [
    "### ğŸ“ Document Your Findings\n",
    "\n",
    "**Issues Found:**\n",
    "\n",
    "| Column | Issue | Examples |\n",
    "|--------|-------|----------|\n",
    "| customer_name | | |\n",
    "| email | | |\n",
    "| phone | | |\n",
    "| order_date | | |\n",
    "| product | | |\n",
    "| quantity | | |\n",
    "| unit_price | | |\n",
    "| status | | |\n",
    "\n",
    "**Most Critical Issues to Fix:**\n",
    "1. \n",
    "2. \n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d1a57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§¹ Activity 2: Collaborative Cleaning (20 min)\n",
    "\n",
    "**ğŸ§¹ Cleaner:** Lead this activity! Write the cleaning code.\n",
    "\n",
    "### ğŸ“‹ Cleaning Tasks\n",
    "1. Remove duplicate orders (keep first)\n",
    "2. Standardize names (title case, strip whitespace)\n",
    "3. Standardize product names (title case)\n",
    "4. Standardize status (title case)\n",
    "5. Convert quantity and price to numeric\n",
    "6. Parse dates to consistent format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4aeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ§¹ ACTIVITY 2: COLLABORATIVE DATA CLEANING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Work together to clean the data!\n",
    "\n",
    "df = messy_orders.copy()\n",
    "print(\"ğŸ§¹ DATA CLEANING PIPELINE\")\n",
    "print(f\"Starting with {len(df)} records\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 1: Remove duplicates\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = df.drop_duplicates(subset=['order_id'], keep='first')\n",
    "print(f\"\\n1ï¸âƒ£ After removing duplicates: {len(df)} records\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 2: Clean customer names\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Handle None strings (the word \"None\" stored as text)\n",
    "df['customer_name'] = df['customer_name'].replace('None', np.nan)\n",
    "# Strip whitespace and standardize case\n",
    "df['customer_name'] = df['customer_name'].str.strip().str.title()\n",
    "# Fix double spaces\n",
    "df['customer_name'] = df['customer_name'].str.replace(r'\\s+', ' ', regex=True)\n",
    "print(\"2ï¸âƒ£ Cleaned customer names\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 3: Standardize product names\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['product'] = df['product'].str.strip().str.title()\n",
    "print(f\"3ï¸âƒ£ Standardized products: {df['product'].unique()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 4: Standardize status\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['status'] = df['status'].str.strip().str.title()\n",
    "# Replace non-standard statuses\n",
    "df['status'] = df['status'].replace('Unknown', np.nan)\n",
    "print(f\"4ï¸âƒ£ Standardized statuses: {df['status'].unique()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 5: Convert quantity to numeric\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')\n",
    "print(\"5ï¸âƒ£ Converted quantity to numeric\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 6: Convert unit_price to numeric\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['unit_price'] = pd.to_numeric(df['unit_price'], errors='coerce')\n",
    "print(\"6ï¸âƒ£ Converted unit_price to numeric\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 7: Parse dates\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')\n",
    "print(\"7ï¸âƒ£ Parsed dates\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# RESULTS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š CLEANED DATA:\")\n",
    "print(df)\n",
    "print(f\"\\nğŸ“‹ Data Types After Cleaning:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1413bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Activity 3: Validation Challenge (15 min)\n",
    "\n",
    "**âœ… Validator:** Lead this activity! Write validation rules.\n",
    "\n",
    "### ğŸ“‹ Validation Rules to Implement\n",
    "1. **Email** - Must contain @ and .\n",
    "2. **Quantity** - Must be positive (> 0) and reasonable (< 1000)\n",
    "3. **Unit Price** - Must be positive\n",
    "4. **Order Date** - Must not be in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… ACTIVITY 3: DATA VALIDATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Apply validation rules to catch remaining issues!\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… DATA VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# VALIDATION 1: Email format\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def is_valid_email(email):\n",
    "    if pd.isna(email) or email == '':\n",
    "        return False\n",
    "    return '@' in str(email) and '.' in str(email).split('@')[-1]\n",
    "\n",
    "df['valid_email'] = df['email'].apply(is_valid_email)\n",
    "invalid_emails = df[~df['valid_email']]\n",
    "print(f\"\\n1ï¸âƒ£ INVALID EMAILS ({len(invalid_emails)}):\")\n",
    "print(invalid_emails[['order_id', 'customer_name', 'email']])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# VALIDATION 2: Quantity\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['valid_quantity'] = (df['quantity'] > 0) & (df['quantity'] < 1000)\n",
    "invalid_qty = df[~df['valid_quantity']]\n",
    "print(f\"\\n2ï¸âƒ£ INVALID QUANTITIES ({len(invalid_qty)}):\")\n",
    "print(invalid_qty[['order_id', 'customer_name', 'quantity']])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# VALIDATION 3: Unit Price\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['valid_price'] = df['unit_price'] > 0\n",
    "invalid_price = df[~df['valid_price']]\n",
    "print(f\"\\n3ï¸âƒ£ INVALID PRICES ({len(invalid_price)}):\")\n",
    "print(invalid_price[['order_id', 'customer_name', 'unit_price']])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# VALIDATION SUMMARY\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š VALIDATION SUMMARY:\")\n",
    "all_valid = df['valid_email'] & df['valid_quantity'] & df['valid_price']\n",
    "print(f\"   Total records: {len(df)}\")\n",
    "print(f\"   Fully valid: {all_valid.sum()}\")\n",
    "print(f\"   Has issues: {(~all_valid).sum()}\")\n",
    "\n",
    "# Clean valid records only\n",
    "df_clean = df[all_valid].copy()\n",
    "df_clean = df_clean.drop(['valid_email', 'valid_quantity', 'valid_price'], axis=1)\n",
    "print(f\"\\nâœ… Clean dataset has {len(df_clean)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a6312",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¬ Team Discussion & Reflection\n",
    "\n",
    "### ğŸ¤” Discussion Questions\n",
    "\n",
    "1. **What was the hardest data issue to fix?**\n",
    "2. **How would you prevent these issues from entering the database in the first place?**\n",
    "3. **What should happen to invalid records?** (Delete? Flag? Quarantine?)\n",
    "4. **How would you automate this cleaning process?**\n",
    "\n",
    "### ğŸ“Š Final Results\n",
    "\n",
    "Run the cell below to see your team's final clean dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ† FINAL RESULTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ† TEAM RESULTS: CLEAN E-COMMERCE DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(df_clean)\n",
    "\n",
    "# Calculate some metrics\n",
    "print(\"\\nğŸ“Š QUICK ANALYSIS ON CLEAN DATA:\")\n",
    "print(f\"   Total Orders: {len(df_clean)}\")\n",
    "print(f\"   Total Revenue: ${(df_clean['quantity'] * df_clean['unit_price']).sum():,.2f}\")\n",
    "print(f\"   Average Order Value: ${(df_clean['quantity'] * df_clean['unit_price']).mean():,.2f}\")\n",
    "print(f\"   Products Sold: {df_clean['product'].unique()}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Great teamwork! Your data is now clean and ready for analysis!\")\n",
    "print(\"ğŸ“š Assignment: Practice cleaning a dataset of your choice\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}