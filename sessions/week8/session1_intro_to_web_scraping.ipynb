{
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":["# Week 8 â€” Introduction to Web Scraping"]},
  {"cell_type":"markdown","metadata":{},"source":["## Learning Objectives","","By the end of this session, you will be able to:\n","* Fetch web pages using Python's urllib standard library\n","* Parse HTML content using html.parser from the standard library\n","* Extract links and simple data from HTML documents\n","* Handle common web scraping errors and edge cases\n","* Understand the ethical considerations of web scraping\n","* Apply web scraping techniques to gather data for analysis"]},
  {"cell_type":"markdown","metadata":{},"source":["### ðŸ”„ JavaScript Transition Note\n","\n","If you're coming from JavaScript/web development, you're probably familiar with the Fetch API or axios for making HTTP requests, and libraries like Cheerio or built-in DOM methods for HTML parsing. Python's urllib provides similar functionality to fetch(), but with a more traditional callback-style API. The html.parser works similarly to DOM parsing, but with a different event-driven approach using handle_starttag() and other methods instead of query selectors. Both approaches achieve the same goal: extracting data from HTML documents."]},
  {"cell_type":"markdown","metadata":{},"source":["### Fetch with urllib"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from urllib.request import urlopen","from urllib.error import URLError","def fetch(url):","    try:","        with urlopen(url) as resp:","            return resp.read().decode('utf-8')","    except URLError as e:","        return ''","html = '<html><body><a href=\"https://example.com\">example</a></body></html>'","print(len(html))"]},
  {"cell_type":"markdown","metadata":{},"source":["**Activity:** Fetch a known URL or use a provided HTML string and print its length."]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pass"]},
  {"cell_type":"markdown","metadata":{},"source":["### Parse Links (html.parser)"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from html.parser import HTMLParser","class LinkParser(HTMLParser):","    def __init__(self):","        super().__init__()","        self.links = []","    def handle_starttag(self, tag, attrs):","        if tag == 'a':","            for k,v in attrs:","                if k == 'href':","                    self.links.append(v)","p = LinkParser()","p.feed('<a href=\"https://a\">A</a> <a href=\"/b\">B</a>')","print(p.links)"]},
  {"cell_type":"markdown","metadata":{},"source":["**Activity:** Parse links from HTML content and filter to absolute URLs only."]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pass"]},
  {"cell_type":"markdown","metadata":{},"source":["### Recap","","Stdlib can fetch and parse simple HTML when external libraries are unavailable."]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3","language": "python","name": "python3"}, "language_info": {"name": "python","version": "3.9.7"}},
 "nbformat": 4,
 "nbformat_minor": 4
}