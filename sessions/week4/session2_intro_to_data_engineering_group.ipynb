{
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":["# Week 4 â€” Group Session: Intro to Data Engineering"]},
  {"cell_type":"markdown","metadata":{},"source":["## Objectives","","- Collaborate on building a simple ETL pipeline.","- Practice CSV and JSON transformations.","- Use roles to divide tasks effectively."]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup: Create data directory and import required modules\nimport csv\nimport json\nfrom pathlib import Path\n\n# Create data directory for file operations\ndata_dir = Path('week4_group_data')\ndata_dir.mkdir(exist_ok=True)\nprint(f\"Data directory created: {data_dir}\")"]},
  {"cell_type":"markdown","metadata":{},"source":["### Activity 1: JSON Lines to CSV"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json, csv","lines = [json.dumps({'name':'ana','score':90}), json.dumps({'name':'bob','score':70})]","jsonl_file = data_dir / 'w4_group.jsonl'","csv_file = data_dir / 'w4_group.csv'","with open(jsonl_file,'w') as f:","    for line in lines:","        f.write(line+'\\n')","with open(jsonl_file,'r') as f:","    rows = [json.loads(x) for x in f.read().splitlines()]","with open(csv_file,'w',newline='') as f:","    w = csv.DictWriter(f, fieldnames=['name','score'])","    w.writeheader()","    w.writerows(rows)","print(rows)"]},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Filter rows to keep only scores >= 80 before writing CSV."
   ]
  },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "import json, csv\n",
      "lines = [json.dumps({'name':'ana','score':90}), json.dumps({'name':'bob','score':70})]\n",
      "jsonl_file = data_dir / 'w4_group.jsonl'\n",
      "csv_file = data_dir / 'w4_group.csv'\n",
      "with open(jsonl_file,'w') as f:\n",
      "    for line in lines:\n",
      "        f.write(line+'\\n')\n",
      "\n",
      "with open(jsonl_file,'r') as f:\n",
      "    rows = [json.loads(x) for x in f.read().splitlines()]\n",
      "\n",
      "filtered_rows = [row for row in rows if row['score'] >= 80]\n",
      "\n",
      "with open(csv_file,'w',newline='') as f:\n",
      "    w = csv.DictWriter(f, fieldnames=['name','score'])\n",
      "    w.writeheader()\n",
      "    w.writerows(filtered_rows)\n",
      "\n",
      "print(filtered_rows)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Activity 2: Directory Processing"
     ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["from pathlib import Path","d = data_dir / 'w4_group_dir'","d.mkdir(exist_ok=True)","for i in range(3):","    Path(d, f'f{i}.txt').write_text(str(i))","contents = [p.read_text() for p in d.iterdir() if p.suffix == '.txt']","print(contents)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Convert all text contents to integers and compute their sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "d = data_dir / 'w4_group_dir'\n",
    "d.mkdir(exist_ok=True)\n",
    "for i in range(3):\n",
    "    Path(d, f'f{i}.txt').write_text(str(i))\n",
    "\n",
    "total = 0\n",
    "for p in d.iterdir():\n",
    "    if p.suffix == '.txt':\n",
    "        total += int(p.read_text())\n",
    "\n",
    "print(f\"The sum is: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš€ Code Challenge: JSON to CSV Pipeline\n",
    "\n",
    "Create a directory called `json_data` inside your data directory. In that directory, create three JSON files, each containing a list of dictionaries. Each dictionary should represent a person with `'name'` and `'age'` keys. \n",
    "\n",
    "Write a Python script that:\n",
    "1. Reads all the JSON files in the `json_data` directory.\n",
    "2. Combines the data from all the files into a single list of dictionaries.\n",
    "3. Writes the combined data to a single CSV file called `summary.csv` in your data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration Guide",
    "",
    "Roles: Data Ingest, Transform, Persist; rotate between activities."
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3","language": "python","name": "python3"}, "language_info": {"name": "python","version": "3.9.7"}},
 "nbformat": 4,
 "nbformat_minor": 4
}