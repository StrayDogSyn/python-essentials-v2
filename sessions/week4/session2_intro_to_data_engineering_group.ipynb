{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¯ Week 4 â€” Group Session: Intro to Data Engineering\n",
        "\n",
        "## ğŸ¤ Collaborative Learning: Building Data Pipelines Together\n",
        "\n",
        "Welcome to the **group session** for Introduction to Data Engineering! In this session, you'll work as a team to build real data processing pipelines using Pandas.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ­ Team Roles (Rotate Each Activity!)\n",
        "\n",
        "| Role | Responsibility | Skills Practiced |\n",
        "|------|---------------|------------------|\n",
        "| ğŸ” **Data Analyst** | Reviews data, checks quality, spots issues | `head()`, `info()`, `describe()` |\n",
        "| ğŸ› ï¸ **Data Engineer** | Writes loading/transformation code | `read_csv()`, filtering, cleaning |\n",
        "| ğŸ“Š **Presenter** | Explains approach, shares findings | Communication, code explanation |\n",
        "| âœ… **QA Tester** | Tests edge cases, validates output | Error handling, validation |\n",
        "\n",
        "**ğŸ’¡ Tip:** Rotate roles after each activity so everyone practices all skills!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“‹ Session Objectives\n",
        "\n",
        "By the end of this group session, your team will be able to:\n",
        "\n",
        "- âœ… Collaborate on building a simple ETL (Extract-Transform-Load) pipeline\n",
        "- âœ… Practice loading and transforming CSV and JSON data with Pandas\n",
        "- âœ… Use team roles to divide tasks effectively\n",
        "- âœ… Debug data issues as a group\n",
        "- âœ… Present your findings and explain your code\n",
        "\n",
        "### â° Session Timeline\n",
        "\n",
        "| Time | Activity |\n",
        "|------|----------|\n",
        "| 0-5 min | Setup & Role Assignment |\n",
        "| 5-20 min | Activity 1: Data Loading Race |\n",
        "| 20-35 min | Activity 2: Transform Challenge |\n",
        "| 35-50 min | Activity 3: Build a Mini Pipeline |\n",
        "| 50-60 min | Share & Discuss |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸš€ SETUP: Run this cell first to prepare your environment\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Create a data directory for our exercises\n",
        "data_dir = Path('week4_group_data')\n",
        "data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"âœ… Setup Complete!\")\n",
        "print(f\"ğŸ“ Data directory: {data_dir.absolute()}\")\n",
        "print(f\"ğŸ¼ Pandas version: {pd.__version__}\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nğŸ­ Don't forget to assign roles before starting!\")\n",
        "print(\"   Roles: Data Analyst, Data Engineer, Presenter, QA Tester\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ Activity 1: Data Loading Race (15 min)\n",
        "\n",
        "**Goal:** Load data and inspect it as quickly and accurately as possible!\n",
        "\n",
        "### ğŸ“‹ Challenge Overview\n",
        "\n",
        "Your team will create and load a sample dataset, then answer questions about it. The **Data Engineer** writes the code, the **Data Analyst** interprets the results, and the **Presenter** will share findings.\n",
        "\n",
        "### ğŸ“Š Step 1: Create Sample Data\n",
        "First, let's create some sample data to work with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ“Š CREATE SAMPLE DATA: Student Grades Dataset\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# This creates a CSV file with student grades for your team to analyze\n",
        "\n",
        "# Create sample student data\n",
        "student_data = \"\"\"student_id,name,course,grade,attendance_pct\n",
        "S001,Alice,Python,92,95\n",
        "S002,Bob,Python,78,80\n",
        "S003,Charlie,Python,85,90\n",
        "S004,Diana,SQL,88,92\n",
        "S005,Eve,SQL,72,75\n",
        "S006,Frank,Python,95,98\n",
        "S007,Grace,SQL,80,85\n",
        "S008,Henry,Python,68,60\n",
        "S009,Ivy,SQL,90,94\n",
        "S010,Jack,Python,82,88\"\"\"\n",
        "\n",
        "# Write to CSV file\n",
        "csv_path = data_dir / 'student_grades.csv'\n",
        "with open(csv_path, 'w') as f:\n",
        "    f.write(student_data)\n",
        "\n",
        "print(\"âœ… Sample data created!\")\n",
        "print(f\"ğŸ“ File: {csv_path}\")\n",
        "print(\"\\nğŸ“‹ Raw data preview:\")\n",
        "print(student_data[:200] + \"...\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸƒ Step 2: Loading Race!\n",
        "\n",
        "**ğŸ” Data Analyst:** Call out what methods to use  \n",
        "**ğŸ› ï¸ Data Engineer:** Write the code  \n",
        "**âœ… QA Tester:** Check if outputs look correct  \n",
        "\n",
        "Load the student_grades.csv file and answer these questions:\n",
        "1. How many students are in the dataset?\n",
        "2. What's the average grade?\n",
        "3. How many students are in each course?\n",
        "4. Who has the highest grade?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸƒ YOUR TEAM'S CODE: Load and Analyze Student Data\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ› ï¸ Data Engineer: Load the CSV file\n",
        "df = pd.read_csv(data_dir / 'student_grades.csv')\n",
        "\n",
        "# ğŸ” Data Analyst: Answer the questions using pandas methods\n",
        "\n",
        "# Question 1: How many students?\n",
        "num_students = len(df)  # or df.shape[0]\n",
        "\n",
        "# Question 2: Average grade?\n",
        "avg_grade = df['grade'].mean()\n",
        "\n",
        "# Question 3: Students per course?\n",
        "course_counts = df['course'].value_counts()\n",
        "\n",
        "# Question 4: Highest grade?\n",
        "top_student = df.loc[df['grade'].idxmax()]\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ“Š RESULTS: Present these to the class\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print(\"ğŸ“Š DATA LOADING RACE RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\n1ï¸âƒ£ Total students: {num_students}\")\n",
        "print(f\"\\n2ï¸âƒ£ Average grade: {avg_grade:.2f}\")\n",
        "print(f\"\\n3ï¸âƒ£ Students per course:\")\n",
        "for course, count in course_counts.items():\n",
        "    print(f\"   {course}: {count} students\")\n",
        "print(f\"\\n4ï¸âƒ£ Top student: {top_student['name']} with grade {top_student['grade']}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ”§ Activity 2: Transform Challenge (15 min)\n",
        "\n",
        "**Goal:** Apply transformations to clean and enhance the data!\n",
        "\n",
        "### ğŸ¯ Challenge Tasks\n",
        "\n",
        "Work as a team to complete these transformations:\n",
        "\n",
        "1. **Filter:** Keep only students with grades >= 80 (B or above)\n",
        "2. **Add Column:** Create a \"status\" column: \"Pass\" if grade >= 70, else \"At Risk\"\n",
        "3. **Sort:** Sort by grade descending\n",
        "4. **Group:** Calculate average grade by course\n",
        "\n",
        "**ğŸ­ Role Rotation:** Switch roles from Activity 1!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸš« BAD PRACTICE: Transformations one at a time, losing data\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# âŒ This approach overwrites the original data - you can't go back!\n",
        "# âŒ No clear workflow\n",
        "\n",
        "print(\"ğŸš« BAD: Overwriting original data\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# DON'T DO THIS - it destroys your original data!\n",
        "# df = df[df['grade'] >= 80]  # Original data is gone!\n",
        "\n",
        "print(\"âŒ Problem: If you filter first, you lose lower grades\")\n",
        "print(\"âŒ Problem: Can't compare before/after\")\n",
        "print(\"âŒ Problem: No way to undo\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸŒ± Novice Approach: Step-by-step transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸŒ± NOVICE: Step-by-step transformations\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# âœ… Keep original data intact\n",
        "# âœ… Clear, readable steps\n",
        "\n",
        "print(\"ğŸŒ± NOVICE: Step-by-step transformations\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Step 1: Keep original data, create a copy\n",
        "df_original = pd.read_csv(data_dir / 'student_grades.csv')\n",
        "df_working = df_original.copy()\n",
        "\n",
        "print(\"Step 1: Data loaded (original preserved)\")\n",
        "print(f\"   Original shape: {df_original.shape}\")\n",
        "\n",
        "# Step 2: Add status column\n",
        "df_working['status'] = 'At Risk'\n",
        "df_working.loc[df_working['grade'] >= 70, 'status'] = 'Pass'\n",
        "\n",
        "print(\"\\nStep 2: Status column added\")\n",
        "print(df_working[['name', 'grade', 'status']].head())\n",
        "\n",
        "# Step 3: Filter for high achievers\n",
        "high_achievers = df_working[df_working['grade'] >= 80]\n",
        "print(f\"\\nStep 3: Filtered to {len(high_achievers)} high achievers (grade >= 80)\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### âœ¨ Pythonic Approach: Method chaining with `.assign()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# âœ¨ PYTHONIC: Method chaining for elegant transformations\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# âœ… Chain operations together\n",
        "# âœ… Readable, self-documenting code\n",
        "# âœ… Original data stays intact\n",
        "\n",
        "print(\"âœ¨ PYTHONIC: Method chaining approach\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# All transformations in one elegant chain\n",
        "result = (\n",
        "    pd.read_csv(data_dir / 'student_grades.csv')\n",
        "    .assign(\n",
        "        # Add status column using numpy-style where\n",
        "        status=lambda x: x['grade'].apply(lambda g: 'Pass' if g >= 70 else 'At Risk'),\n",
        "        # Add letter grade for fun\n",
        "        letter_grade=lambda x: x['grade'].apply(\n",
        "            lambda g: 'A' if g >= 90 else 'B' if g >= 80 else 'C' if g >= 70 else 'D' if g >= 60 else 'F'\n",
        "        )\n",
        "    )\n",
        "    .sort_values('grade', ascending=False)  # Sort by grade descending\n",
        ")\n",
        "\n",
        "print(\"ğŸ“Š Transformed Data (sorted by grade):\")\n",
        "print(result[['name', 'course', 'grade', 'letter_grade', 'status']])\n",
        "\n",
        "# Group statistics\n",
        "print(\"\\nğŸ“ˆ Average Grade by Course:\")\n",
        "print(result.groupby('course')['grade'].mean().round(2))\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸš€ Activity 3: Build a Mini ETL Pipeline (15 min)\n",
        "\n",
        "**Goal:** Build a complete Extract-Transform-Load pipeline as a team!\n",
        "\n",
        "### ğŸ“‹ The Pipeline Challenge\n",
        "\n",
        "Your team needs to build a data pipeline that:\n",
        "\n",
        "1. **EXTRACT:** Load the student grades data\n",
        "2. **TRANSFORM:**\n",
        "   - Add a \"performance\" column: \"Excellent\" (90+), \"Good\" (80-89), \"Average\" (70-79), \"Needs Help\" (<70)\n",
        "   - Add an \"at_risk\" flag for students with attendance < 80%\n",
        "   - Calculate a \"weighted_score\" = (grade * 0.7) + (attendance * 0.3)\n",
        "3. **LOAD:** Save the enhanced data to a new CSV file\n",
        "\n",
        "**ğŸ­ Suggested Role Division:**\n",
        "- **Data Analyst:** Design the transformation logic\n",
        "- **Data Engineer:** Write the pipeline code  \n",
        "- **QA Tester:** Validate the output\n",
        "- **Presenter:** Document and explain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸš€ YOUR TEAM'S ETL PIPELINE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Work together to complete this pipeline!\n",
        "\n",
        "def get_performance(grade):\n",
        "    \"\"\"Categorize student performance based on grade.\"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Return \"Excellent\" for 90+\n",
        "    # Return \"Good\" for 80-89\n",
        "    # Return \"Average\" for 70-79\n",
        "    # Return \"Needs Help\" for below 70\n",
        "    if grade >= 90:\n",
        "        return \"Excellent\"\n",
        "    elif grade >= 80:\n",
        "        return \"Good\"\n",
        "    elif grade >= 70:\n",
        "        return \"Average\"\n",
        "    else:\n",
        "        return \"Needs Help\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# STEP 1: EXTRACT\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸ”„ STEP 1: EXTRACT\")\n",
        "df = pd.read_csv(data_dir / 'student_grades.csv')\n",
        "print(f\"   Loaded {len(df)} records\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# STEP 2: TRANSFORM\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\nğŸ”„ STEP 2: TRANSFORM\")\n",
        "\n",
        "# Add performance column\n",
        "df['performance'] = df['grade'].apply(get_performance)\n",
        "print(\"   âœ“ Added 'performance' column\")\n",
        "\n",
        "# Add at_risk flag\n",
        "df['at_risk'] = df['attendance_pct'] < 80\n",
        "print(\"   âœ“ Added 'at_risk' flag\")\n",
        "\n",
        "# Calculate weighted score\n",
        "df['weighted_score'] = (df['grade'] * 0.7) + (df['attendance_pct'] * 0.3)\n",
        "df['weighted_score'] = df['weighted_score'].round(2)\n",
        "print(\"   âœ“ Added 'weighted_score' column\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# STEP 3: LOAD\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\nğŸ”„ STEP 3: LOAD\")\n",
        "output_path = data_dir / 'student_grades_enhanced.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"   âœ“ Saved to {output_path}\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# RESULTS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ‰ ETL PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nğŸ“Š Enhanced Data Preview:\")\n",
        "print(df[['name', 'grade', 'performance', 'at_risk', 'weighted_score']])\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nğŸ“ˆ Performance Distribution:\")\n",
        "print(df['performance'].value_counts())\n",
        "\n",
        "print(\"\\nâš ï¸ At-Risk Students:\")\n",
        "at_risk = df[df['at_risk'] == True]\n",
        "if len(at_risk) > 0:\n",
        "    print(at_risk[['name', 'grade', 'attendance_pct']])\n",
        "else:\n",
        "    print(\"   No at-risk students!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ† Bonus Challenge: Production-Ready Pipeline\n",
        "\n",
        "**For teams who finish early!** Refactor the ETL pipeline into a reusable class with error handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ† BONUS: Production-Ready ETL Pipeline Class\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# âœ¨ This is how professionals structure ETL pipelines!\n",
        "\n",
        "class StudentETL:\n",
        "    \"\"\"\n",
        "    A production-ready ETL pipeline for student data.\n",
        "    \n",
        "    Attributes:\n",
        "        source_path: Path to source CSV file\n",
        "        output_path: Path for output CSV file\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, source_path, output_path):\n",
        "        self.source_path = Path(source_path)\n",
        "        self.output_path = Path(output_path)\n",
        "        self.df = None\n",
        "        self.stats = {}\n",
        "    \n",
        "    def extract(self):\n",
        "        \"\"\"Load data from source file.\"\"\"\n",
        "        if not self.source_path.exists():\n",
        "            raise FileNotFoundError(f\"Source file not found: {self.source_path}\")\n",
        "        \n",
        "        self.df = pd.read_csv(self.source_path)\n",
        "        self.stats['records_extracted'] = len(self.df)\n",
        "        print(f\"âœ… EXTRACT: Loaded {len(self.df)} records\")\n",
        "        return self\n",
        "    \n",
        "    def transform(self):\n",
        "        \"\"\"Apply all transformations.\"\"\"\n",
        "        if self.df is None:\n",
        "            raise ValueError(\"No data to transform! Run extract() first.\")\n",
        "        \n",
        "        # Add performance category\n",
        "        self.df['performance'] = self.df['grade'].apply(self._get_performance)\n",
        "        \n",
        "        # Add risk flag\n",
        "        self.df['at_risk'] = self.df['attendance_pct'] < 80\n",
        "        \n",
        "        # Add weighted score\n",
        "        self.df['weighted_score'] = (\n",
        "            (self.df['grade'] * 0.7) + (self.df['attendance_pct'] * 0.3)\n",
        "        ).round(2)\n",
        "        \n",
        "        self.stats['records_transformed'] = len(self.df)\n",
        "        self.stats['at_risk_count'] = self.df['at_risk'].sum()\n",
        "        print(f\"âœ… TRANSFORM: Processed {len(self.df)} records\")\n",
        "        return self\n",
        "    \n",
        "    def load(self):\n",
        "        \"\"\"Save transformed data to output file.\"\"\"\n",
        "        if self.df is None:\n",
        "            raise ValueError(\"No data to load! Run extract() and transform() first.\")\n",
        "        \n",
        "        self.df.to_csv(self.output_path, index=False)\n",
        "        self.stats['records_loaded'] = len(self.df)\n",
        "        print(f\"âœ… LOAD: Saved to {self.output_path}\")\n",
        "        return self\n",
        "    \n",
        "    def run(self):\n",
        "        \"\"\"Execute the full ETL pipeline.\"\"\"\n",
        "        return self.extract().transform().load()\n",
        "    \n",
        "    @staticmethod\n",
        "    def _get_performance(grade):\n",
        "        \"\"\"Categorize performance level.\"\"\"\n",
        "        if grade >= 90: return \"Excellent\"\n",
        "        if grade >= 80: return \"Good\"\n",
        "        if grade >= 70: return \"Average\"\n",
        "        return \"Needs Help\"\n",
        "    \n",
        "    def get_summary(self):\n",
        "        \"\"\"Return pipeline execution summary.\"\"\"\n",
        "        return self.stats\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# USE THE PRODUCTION PIPELINE\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"ğŸ† BONUS: Running Production ETL Pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "etl = StudentETL(\n",
        "    source_path=data_dir / 'student_grades.csv',\n",
        "    output_path=data_dir / 'student_grades_production.csv'\n",
        ")\n",
        "\n",
        "# Run the pipeline (method chaining!)\n",
        "etl.run()\n",
        "\n",
        "print(\"\\nğŸ“Š Pipeline Summary:\")\n",
        "for key, value in etl.get_summary().items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "print(\"\\nâœ¨ This is how real data engineers write pipelines!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ’¬ Discussion & Reflection (10 min)\n",
        "\n",
        "### ğŸ¤” Team Discussion Questions\n",
        "\n",
        "1. **What was the hardest part** of building the ETL pipeline?\n",
        "2. **What would break** if the input data had missing values?\n",
        "3. **How would you modify** the pipeline to handle multiple input files?\n",
        "4. **What did you learn** from your teammates?\n",
        "\n",
        "### ğŸ“ Key Takeaways\n",
        "\n",
        "| Concept | What We Learned |\n",
        "|---------|-----------------|\n",
        "| **ETL** | Extract-Transform-Load is the standard pattern |\n",
        "| **Method Chaining** | `.assign()` lets us chain transformations |\n",
        "| **Data Validation** | Always check data before/after transformations |\n",
        "| **Teamwork** | Different roles bring different perspectives |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ§¹ CLEANUP: Remove temporary files\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import shutil\n",
        "\n",
        "# Clean up the data directory\n",
        "if data_dir.exists():\n",
        "    shutil.rmtree(data_dir)\n",
        "    print(\"âœ… Cleaned up temporary files\")\n",
        "\n",
        "print(\"\\nğŸ‰ Great teamwork! See you next week!\")\n",
        "print(\"ğŸ“š Assignment: Practice building your own ETL pipeline\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
