{
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":["# Week 4 â€” Intro to Data Engineering"]},
  {"cell_type":"markdown","metadata":{},"source":["## Objectives","","- Use the filesystem via `pathlib` and `os`.","- Read and write CSV and JSON using the standard library.","- Build small data pipelines with pure Python."]},
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Create data directory and import required modules\n",
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create data directory for file operations\n",
    "data_dir = Path('week4_data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "print(f\"Data directory created: {data_dir}\")"
   ]
  },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesystem Basics\n",
    "\n",
    "The `pathlib` module provides an object-oriented interface for working with filesystem paths. It is the modern and recommended way to handle filesystem paths in Python, as it is more intuitive and less error-prone than using strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standardized data directory\n",
    "p = data_dir\n",
    "p.mkdir(exist_ok=True)\n",
    "print(p.exists())"
   ]
,
     "source": [
      "**Activity:** Create a new directory and list its contents."
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "new_dir = Path('my_new_directory')\n",
      "new_dir.mkdir(exist_ok=True)\n",
      "print(f\"Directory '{new_dir}' created.\")\n",
      "print(f\"Contents of '.': {list(Path('.').iterdir())}\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### CSV Read/Write (stdlib)"
     ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import csv","rows = [{'name':'ana','score':90},{'name':'bob','score':75}]","csv_file = data_dir / 'data.csv'","with open(csv_file,'w',newline='') as f:","    w = csv.DictWriter(f, fieldnames=['name','score'])","    w.writeheader()","    w.writerows(rows)","with open(csv_file,'r') as f:","    r = csv.DictReader(f)","    print(list(r))"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity:** Read the CSV and print names with scores >= 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_file, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if int(row['score']) >= 80:\n",
    "            print(row['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Read/Write (stdlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import json","data = {'title':'example','items':[1,2,3]}","json_file = data_dir / 'data.json'","with open(json_file,'w') as f:","    json.dump(data, f)","with open(json_file,'r') as f:","    loaded = json.load(f)","print(loaded)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["**Activity:** Load JSON and add a new key-value pair, then write it back."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["pass"]
  },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Pipeline\n",
    "\n",
    "A data pipeline is a series of steps that move data from a source to a destination. Along the way, the data is transformed and enriched. In this example, we are creating a simple pipeline that reads raw data from a CSV file, cleans it up, and then writes the clean data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create raw data file\n",
    "raw_file = data_dir / 'raw.csv'\n",
    "import csv","with open(raw_file,'w',newline='') as f:","    w = csv.writer(f)","    w.writerow(['name','age'])","    w.writerow(['ana','30'])","    w.writerow(['bob','x'])","clean = []","with open(raw_file,'r') as f:","    r = csv.DictReader(f)","    for row in r:","        try:","            age = int(row['age'])","            clean.append({'name':row['name'],'age':age})","        except Exception:","            pass","clean_file = data_dir / 'clean.csv'","with open(clean_file,'w',newline='') as f:","    w = csv.DictWriter(f, fieldnames=['name','age'])","    w.writeheader()","    w.writerows(clean)","print(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity:** Extend the pipeline to compute the average age from `clean.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_age = 0\n",
    "num_records = 0\n",
    "with open(clean_file, 'r') as f:",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        total_age += int(row['age'])\n",
    "        num_records += 1\n",
    "\n",
    "if num_records > 0:\n",
    "    average_age = total_age / num_records\n",
    "    print(f\"Average age: {average_age:.2f}\")\n",
    "else:\n",
    "    print(\"No records found.\")"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap",
    "",
    "Pure Python tools can cover filesystem and simple data tasks without external libraries."
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3","language": "python","name": "python3"}, "language_info": {"name": "python","version": "3.9.7"}},
 "nbformat": 4,
 "nbformat_minor": 4
}