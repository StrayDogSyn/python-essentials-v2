{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6808392",
   "metadata": {},
   "source": [
    "# ğŸ“š Week 4 â€” Introduction to Data Engineering with Pandas\n",
    "\n",
    "---\n",
    "\n",
    "## Welcome to Week 4!\n",
    "\n",
    "This interactive notebook introduces you to **Pandas**, Python's most powerful library for data analysis and manipulation. You'll learn to work with structured data like a professional data engineer!\n",
    "\n",
    "| Icon | Meaning |\n",
    "|------|---------|\n",
    "| ğŸš« | **Broken/Bad Practice** â€” Common mistakes to avoid |\n",
    "| ğŸŒ± | **Novice Solution** â€” Basic working approach |\n",
    "| ğŸ”§ | **Intermediate Solution** â€” Better structure and readability |\n",
    "| âœ¨ | **Pythonic Best Practice** â€” Clean, idiomatic Python with Pandas |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘‰ How to Use This Notebook:\n",
    "\n",
    "1. Run each code cell by pressing `Shift + Enter`\n",
    "2. Experiment with the code â€” change values and see what happens!\n",
    "3. Complete the activities to test your understanding\n",
    "4. Read the comments carefully â€” they explain the \"why\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e5371",
   "metadata": {},
   "source": [
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "\n",
    "| # | Skill | Description |\n",
    "|---|-------|-------------|\n",
    "| 1 | **Introduction to Pandas** | Understand why Pandas is essential for data work |\n",
    "| 2 | **Series** | Create and manipulate one-dimensional labeled data |\n",
    "| 3 | **DataFrames** | Create and work with two-dimensional tabular data |\n",
    "| 4 | **Loading Data** | Read data from CSV, JSON, and dictionaries |\n",
    "| 5 | **Data Inspection** | Use `head()`, `tail()`, `info()`, `describe()` to explore data |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ef995",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“– Section 1: Introduction to Pandas\n",
    "\n",
    "---\n",
    "\n",
    "## What is Pandas?\n",
    "\n",
    "**Pandas** is a powerful, open-source library for data analysis and manipulation in Python. It provides data structures that make working with structured data fast, easy, and expressive.\n",
    "\n",
    "### ğŸ”‘ Why Use Pandas?\n",
    "\n",
    "| Without Pandas | With Pandas |\n",
    "|----------------|-------------|\n",
    "| Manual loops to process data | Vectorized operations (fast!) |\n",
    "| Complex code for file I/O | One-line data loading |\n",
    "| Difficult data cleaning | Built-in cleaning methods |\n",
    "| No data alignment | Automatic index alignment |\n",
    "\n",
    "### ğŸ“Š Key Data Structures\n",
    "\n",
    "| Structure | Dimensions | Description | Example Use |\n",
    "|-----------|------------|-------------|-------------|\n",
    "| **Series** | 1D | Labeled array | A column of ages |\n",
    "| **DataFrame** | 2D | Labeled table | A spreadsheet of data |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2301141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“¦ SETUP: Import Pandas and Create Working Directory\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# First, we import pandas with the standard alias 'pd'\n",
    "# This is a universal convention in the Python data science community\n",
    "\n",
    "import pandas as pd                      # <- Standard import alias\n",
    "import numpy as np                       # <- Often used with pandas\n",
    "from pathlib import Path                 # <- For file path operations\n",
    "\n",
    "# Create a directory for our data files\n",
    "data_dir = Path('week4_data')\n",
    "data_dir.mkdir(exist_ok=True)            # Create if it doesn't exist\n",
    "\n",
    "print(\"âœ… Pandas imported successfully!\")\n",
    "print(f\"ğŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ“ Data directory: {data_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b388add",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“– Section 2: Pandas Series\n",
    "\n",
    "---\n",
    "\n",
    "## What is a Series?\n",
    "\n",
    "A **Series** is a one-dimensional labeled array. Think of it as a single column from a spreadsheet, where each value has an associated label (index).\n",
    "\n",
    "### ğŸ§© Series Components\n",
    "\n",
    "```\n",
    "Index    Data\n",
    "â”€â”€â”€â”€â”€    â”€â”€â”€â”€\n",
    "  0   â†’   10\n",
    "  1   â†’   20\n",
    "  2   â†’   30\n",
    "```\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Index** | Labels for each element (default: 0, 1, 2, ...) |\n",
    "| **Data** | The actual values |\n",
    "| **Name** | Optional name for the series |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ EXAMPLE 1: Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸš« BAD PRACTICE: Using Python lists for data operations\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš ï¸ PROBLEMS:\n",
    "#    1. Slow for large datasets (no vectorization)\n",
    "#    2. Manual indexing is error-prone\n",
    "#    3. No built-in data analysis methods\n",
    "\n",
    "# Using a plain Python list\n",
    "ages_list = [25, 30, 35, 40, 45]\n",
    "\n",
    "# To double all values, you need a loop or comprehension\n",
    "doubled_list = [age * 2 for age in ages_list]\n",
    "\n",
    "# To get statistics, you need to write functions\n",
    "average = sum(ages_list) / len(ages_list)\n",
    "\n",
    "print(\"ğŸš« BAD PRACTICE: Using plain lists\")\n",
    "print(f\"   Original: {ages_list}\")\n",
    "print(f\"   Doubled: {doubled_list}\")\n",
    "print(f\"   Average: {average}\")\n",
    "print(\"   âš ï¸ Problem: Manual operations, no labels, slow for big data\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸŒ± NOVICE SOLUTION: Basic Series creation\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Uses Pandas, but doesn't leverage all features\n",
    "\n",
    "# Create a Series from a list\n",
    "ages_series = pd.Series([25, 30, 35, 40, 45])\n",
    "\n",
    "print(\"ğŸŒ± NOVICE SOLUTION: Basic Series\")\n",
    "print(ages_series)\n",
    "print(f\"\\n   Type: {type(ages_series)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d99bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”§ INTERMEDIATE SOLUTION: Series with custom index\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Uses meaningful labels instead of default numeric index\n",
    "\n",
    "# Create a Series with custom index labels\n",
    "ages_labeled = pd.Series(\n",
    "    data=[25, 30, 35, 40, 45],            # The values\n",
    "    index=['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],  # Custom labels\n",
    "    name='Age'                            # Name for the series\n",
    ")\n",
    "\n",
    "print(\"ğŸ”§ INTERMEDIATE SOLUTION: Labeled Series\")\n",
    "print(ages_labeled)\n",
    "\n",
    "# Access by label\n",
    "print(f\"\\n   Alice's age: {ages_labeled['Alice']}\")\n",
    "print(f\"   Bob's age: {ages_labeled['Bob']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ¨ PYTHONIC BEST PRACTICE: Full Series capabilities\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Leverages vectorized operations and built-in methods\n",
    "\n",
    "# Create a well-documented Series\n",
    "ages = pd.Series(\n",
    "    data=[25, 30, 35, 40, 45],\n",
    "    index=['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    name='Age',\n",
    "    dtype='int64'                         # Explicit data type\n",
    ")\n",
    "\n",
    "print(\"âœ¨ PYTHONIC BEST PRACTICE: Full Series Power\")\n",
    "print(ages)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# VECTORIZED OPERATIONS: No loops needed!\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“Š Vectorized Operations (no loops!):\")\n",
    "print(f\"   Double all ages: {list(ages * 2)}\")\n",
    "print(f\"   Add 5 years: {list(ages + 5)}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# BUILT-IN STATISTICS: One method call!\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“ˆ Built-in Statistics:\")\n",
    "print(f\"   Mean: {ages.mean()}\")\n",
    "print(f\"   Min: {ages.min()}, Max: {ages.max()}\")\n",
    "print(f\"   Sum: {ages.sum()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FILTERING: Boolean indexing\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ” Filtering (ages > 30):\")\n",
    "print(ages[ages > 30])\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e5ab2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“– Section 3: Pandas DataFrames\n",
    "\n",
    "---\n",
    "\n",
    "## What is a DataFrame?\n",
    "\n",
    "A **DataFrame** is a two-dimensional labeled data structure â€” like a spreadsheet or SQL table. It's the most commonly used Pandas object.\n",
    "\n",
    "### ğŸ§© DataFrame Components\n",
    "\n",
    "```\n",
    "         Column A   Column B   Column C\n",
    "         â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Row 0  â†’    10         'a'        True\n",
    "Row 1  â†’    20         'b'        False\n",
    "Row 2  â†’    30         'c'        True\n",
    "```\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Index** | Row labels (default: 0, 1, 2, ...) |\n",
    "| **Columns** | Column names |\n",
    "| **Data** | The actual values (can be different types per column) |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ EXAMPLE 2: Creating a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸš« BAD PRACTICE: Using nested lists/dicts without Pandas\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš ï¸ PROBLEMS:\n",
    "#    1. Hard to access specific columns\n",
    "#    2. No built-in methods for analysis\n",
    "#    3. Difficult to add/remove data\n",
    "\n",
    "# Nested list approach (BAD)\n",
    "data_nested = [\n",
    "    ['Alice', 25, 'NYC'],\n",
    "    ['Bob', 30, 'LA'],\n",
    "    ['Charlie', 35, 'Chicago']\n",
    "]\n",
    "\n",
    "# To get all ages, you need a loop\n",
    "ages_bad = [row[1] for row in data_nested]\n",
    "\n",
    "print(\"ğŸš« BAD PRACTICE: Nested lists\")\n",
    "print(f\"   Data: {data_nested}\")\n",
    "print(f\"   Ages: {ages_bad}\")\n",
    "print(\"   âš ï¸ Problem: Accessing by index (row[1]) is unclear and error-prone\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a440f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸŒ± NOVICE SOLUTION: DataFrame from list of lists\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Uses Pandas, but column names are added separately\n",
    "\n",
    "data_list = [\n",
    "    ['Alice', 25, 'NYC'],\n",
    "    ['Bob', 30, 'LA'],\n",
    "    ['Charlie', 35, 'Chicago']\n",
    "]\n",
    "\n",
    "# Create DataFrame and add column names\n",
    "df_novice = pd.DataFrame(data_list)\n",
    "df_novice.columns = ['Name', 'Age', 'City']  # Add names after creation\n",
    "\n",
    "print(\"ğŸŒ± NOVICE SOLUTION: DataFrame from list\")\n",
    "print(df_novice)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6655fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”§ INTERMEDIATE SOLUTION: DataFrame from dictionary\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Column names are keys, cleaner syntax\n",
    "\n",
    "data_dict = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['NYC', 'LA', 'Chicago']\n",
    "}\n",
    "\n",
    "df_intermediate = pd.DataFrame(data_dict)\n",
    "\n",
    "print(\"ğŸ”§ INTERMEDIATE SOLUTION: DataFrame from dict\")\n",
    "print(df_intermediate)\n",
    "\n",
    "# Access a column easily\n",
    "print(f\"\\n   Ages column: {list(df_intermediate['Age'])}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28605aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ¨ PYTHONIC BEST PRACTICE: Full DataFrame capabilities\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Uses all DataFrame features for data analysis\n",
    "\n",
    "# Create a more complete dataset\n",
    "employees = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 42],\n",
    "    'Department': ['Engineering', 'Marketing', 'Engineering', 'Sales', 'Marketing'],\n",
    "    'Salary': [75000, 65000, 85000, 60000, 90000],\n",
    "    'Start_Date': pd.to_datetime(['2020-01-15', '2019-06-01', '2018-03-20', \n",
    "                                   '2021-09-10', '2017-11-30'])\n",
    "})\n",
    "\n",
    "print(\"âœ¨ PYTHONIC BEST PRACTICE: Complete DataFrame\")\n",
    "print(employees)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COLUMN ACCESS: Multiple ways\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“Š Column Access Methods:\")\n",
    "print(f\"   employees['Age']: {list(employees['Age'])}\")\n",
    "print(f\"   employees.Age: {list(employees.Age)}\")  # Dot notation (if no spaces)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FILTERING: Boolean indexing\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ” Filtering (Salary > 70000):\")\n",
    "high_earners = employees[employees['Salary'] > 70000]\n",
    "print(high_earners[['Name', 'Salary']])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# QUICK STATISTICS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“ˆ Quick Statistics:\")\n",
    "print(f\"   Average Salary: ${employees['Salary'].mean():,.2f}\")\n",
    "print(f\"   Total Employees: {len(employees)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6051fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‚ Section 4: Loading Data from Files\n",
    "\n",
    "Data engineers rarely type data by hand! Real data comes from **CSV files**, **JSON files**, **databases**, and **APIs**.\n",
    "\n",
    "### ğŸ“‹ Common Data Sources\n",
    "\n",
    "| Source | Use Case | Pandas Method |\n",
    "|--------|----------|---------------|\n",
    "| CSV | Tabular data, spreadsheets | `pd.read_csv()` |\n",
    "| JSON | Web APIs, configs | `pd.read_json()` |\n",
    "| Excel | Business reports | `pd.read_excel()` |\n",
    "| SQL | Databases | `pd.read_sql()` |\n",
    "\n",
    "**ğŸ’¡ Learning Goal:** Master CSV and JSON loading with proper error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸš« BAD PRACTICE: Loading data without checks\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âŒ No error handling\n",
    "# âŒ Assuming file exists\n",
    "# âŒ No validation of loaded data\n",
    "\n",
    "# This would CRASH if file doesn't exist:\n",
    "# df = pd.read_csv(\"data.csv\")  # FileNotFoundError!\n",
    "# print(df)\n",
    "\n",
    "print(\"ğŸš« BAD: Assuming files exist without checking\")\n",
    "print(\"   df = pd.read_csv('data.csv')  # Will crash if missing!\")\n",
    "print(\"\\nâŒ Problems:\")\n",
    "print(\"   1. No file existence check\")\n",
    "print(\"   2. No error handling\")\n",
    "print(\"   3. No data validation\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸŒ± NOVICE: Create sample CSV and load with basic check\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Creates sample data for practice\n",
    "# âœ… Simple file existence check\n",
    "\n",
    "import os\n",
    "\n",
    "# First, let's create a sample CSV file to work with\n",
    "sample_csv = \"\"\"name,age,city,salary\n",
    "Alice,25,New York,75000\n",
    "Bob,30,Los Angeles,65000\n",
    "Charlie,35,Chicago,85000\n",
    "Diana,28,Houston,60000\n",
    "Eve,42,Phoenix,90000\"\"\"\n",
    "\n",
    "# Write sample CSV\n",
    "with open('sample_employees.csv', 'w') as f:\n",
    "    f.write(sample_csv)\n",
    "\n",
    "print(\"ğŸŒ± NOVICE: Loading CSV with basic check\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check if file exists before loading\n",
    "if os.path.exists('sample_employees.csv'):\n",
    "    df = pd.read_csv('sample_employees.csv')\n",
    "    print(\"âœ… File loaded successfully!\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"âŒ File not found!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebdb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”§ INTERMEDIATE: Try/except with CSV parameters\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Uses try/except for error handling\n",
    "# âœ… Specifies useful read_csv parameters\n",
    "\n",
    "print(\"ğŸ”§ INTERMEDIATE: Loading CSV with try/except and parameters\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    # read_csv has many useful parameters:\n",
    "    df = pd.read_csv(\n",
    "        'sample_employees.csv',\n",
    "        # index_col=0,           # Use first column as index\n",
    "        # usecols=['name', 'salary'],  # Only load specific columns\n",
    "        dtype={'salary': int}    # Specify data types\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… File loaded with custom parameters!\")\n",
    "    print(f\"   Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "    print(f\"   Data types:\\n{df.dtypes}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ File not found! Check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"âŒ File is empty!\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"âŒ Error parsing the file!\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ¨ PYTHONIC: Production-ready data loading function\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Reusable function\n",
    "# âœ… Comprehensive error handling  \n",
    "# âœ… Returns None on failure (easy to check)\n",
    "# âœ… Includes validation\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def load_csv_safely(filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Load a CSV file with comprehensive error handling.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the CSV file\n",
    "        **kwargs: Additional arguments passed to pd.read_csv()\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame if successful, None if failed\n",
    "    \"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    \n",
    "    # Check file exists\n",
    "    if not filepath.exists():\n",
    "        print(f\"âŒ File not found: {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    # Check file extension\n",
    "    if filepath.suffix.lower() != '.csv':\n",
    "        print(f\"âš ï¸ Warning: File may not be CSV: {filepath.suffix}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(filepath, **kwargs)\n",
    "        \n",
    "        # Validate loaded data\n",
    "        if df.empty:\n",
    "            print(\"âš ï¸ Warning: DataFrame is empty\")\n",
    "        \n",
    "        print(f\"âœ… Loaded {len(df)} rows, {len(df.columns)} columns from {filepath.name}\")\n",
    "        return df\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"âŒ File is empty: {filepath}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"âŒ Parse error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"âœ¨ PYTHONIC: Production-ready CSV loading\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Use our safe loading function\n",
    "df = load_csv_safely('sample_employees.csv')\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\nğŸ“Š Data Preview:\")\n",
    "    print(df.head())\n",
    "\n",
    "# Test with non-existent file (won't crash!)\n",
    "print(\"\\nğŸ“ Testing with missing file:\")\n",
    "result = load_csv_safely('nonexistent.csv')\n",
    "print(f\"   Result: {result}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d1b1d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” Section 5: Data Inspection - Your First Analysis Steps\n",
    "\n",
    "After loading data, **always inspect it first!** This helps you understand:\n",
    "- What columns exist?\n",
    "- What data types are present?\n",
    "- Are there missing values?\n",
    "- What do the values look like?\n",
    "\n",
    "### ğŸ“‹ Essential Inspection Methods\n",
    "\n",
    "| Method | What It Shows |\n",
    "|--------|---------------|\n",
    "| `.head(n)` | First n rows (default 5) |\n",
    "| `.tail(n)` | Last n rows |\n",
    "| `.shape` | (rows, columns) tuple |\n",
    "| `.info()` | Column types, memory, non-null counts |\n",
    "| `.describe()` | Statistics for numeric columns |\n",
    "| `.columns` | List of column names |\n",
    "| `.dtypes` | Data type of each column |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸš« BAD PRACTICE: Just printing the entire DataFrame\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âŒ With large data, this crashes your notebook or floods output\n",
    "# âŒ No understanding of data structure\n",
    "\n",
    "print(\"ğŸš« BAD: Just printing everything\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create larger sample data\n",
    "large_df = pd.DataFrame({\n",
    "    'id': range(1000),\n",
    "    'value': [x * 1.5 for x in range(1000)],\n",
    "    'category': ['A', 'B', 'C'] * 333 + ['A']\n",
    "})\n",
    "\n",
    "# BAD: Don't do this with large data!\n",
    "# print(large_df)  # Would print 1000 rows!\n",
    "\n",
    "print(\"âŒ Don't use: print(df) with large datasets!\")\n",
    "print(\"   This would print all 1000 rows!\")\n",
    "print(f\"   DataFrame has {len(large_df)} rows\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81117860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸŒ± NOVICE: Basic inspection methods\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Uses head() and tail() to see data samples\n",
    "\n",
    "print(\"ğŸŒ± NOVICE: Basic data inspection\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# See first 5 rows\n",
    "print(\"ğŸ“‹ First 5 rows (head()):\")\n",
    "print(large_df.head())\n",
    "\n",
    "print(\"\\nğŸ“‹ Last 3 rows (tail(3)):\")\n",
    "print(large_df.tail(3))\n",
    "\n",
    "print(\"\\nğŸ“ Shape:\")\n",
    "print(f\"   {large_df.shape[0]} rows Ã— {large_df.shape[1]} columns\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec211b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”§ INTERMEDIATE: Combining inspection methods\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Uses info() for complete overview\n",
    "# âœ… Uses describe() for statistics\n",
    "\n",
    "print(\"ğŸ”§ INTERMEDIATE: Detailed data inspection\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create data with some complexity\n",
    "products = pd.DataFrame({\n",
    "    'product_id': [101, 102, 103, 104, 105],\n",
    "    'name': ['Widget', 'Gadget', 'Gizmo', 'Doohickey', 'Thingamajig'],\n",
    "    'price': [29.99, 49.99, 19.99, 39.99, None],  # Note: None = missing value!\n",
    "    'quantity': [100, 50, 200, 75, 30],\n",
    "    'category': ['Tools', 'Electronics', 'Tools', 'Home', 'Electronics']\n",
    "})\n",
    "\n",
    "print(\"ğŸ“‹ Data Sample:\")\n",
    "print(products.head())\n",
    "\n",
    "print(\"\\nğŸ“Š DataFrame Info:\")\n",
    "products.info()\n",
    "\n",
    "print(\"\\nğŸ“ˆ Statistical Summary (numeric columns):\")\n",
    "print(products.describe())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2773c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ¨ PYTHONIC: Complete data profiling function\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœ… Reusable function for any DataFrame\n",
    "# âœ… Checks for missing values\n",
    "# âœ… Provides actionable insights\n",
    "\n",
    "def profile_dataframe(df, name=\"DataFrame\"):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive profile of a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: The pandas DataFrame to profile\n",
    "        name: A name for the DataFrame (for display)\n",
    "    \"\"\"\n",
    "    print(f\"âœ¨ DATA PROFILE: {name}\")\n",
    "    print(\"â•\" * 60)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"ğŸ“ Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "    print(f\"ğŸ’¾ Memory: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "    \n",
    "    # Column details\n",
    "    print(f\"\\nğŸ“‹ Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Data types summary\n",
    "    print(\"\\nğŸ·ï¸ Data Types:\")\n",
    "    for dtype, count in df.dtypes.value_counts().items():\n",
    "        print(f\"   {dtype}: {count} columns\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.any():\n",
    "        print(\"\\nâš ï¸ Missing Values:\")\n",
    "        for col, count in missing[missing > 0].items():\n",
    "            pct = count / len(df) * 100\n",
    "            print(f\"   {col}: {count} ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\nâœ… No missing values!\")\n",
    "    \n",
    "    # Numeric summary\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nğŸ“Š Numeric Columns Summary:\")\n",
    "        print(df[numeric_cols].describe().round(2))\n",
    "    \n",
    "    # Categorical summary\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(f\"\\nğŸ·ï¸ Categorical Columns:\")\n",
    "        for col in cat_cols:\n",
    "            unique = df[col].nunique()\n",
    "            print(f\"   {col}: {unique} unique values\")\n",
    "    \n",
    "    print(\"â•\" * 60)\n",
    "\n",
    "\n",
    "# Use our profiling function\n",
    "profile_dataframe(products, \"Products Inventory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608d1d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Section 6: Interactive Practice Activities\n",
    "\n",
    "Now it's your turn! Complete these exercises to reinforce what you've learned.\n",
    "\n",
    "### ğŸ‹ï¸ Activity 1: Create Your Own DataFrame\n",
    "Create a DataFrame with at least 4 columns and 5 rows representing data you find interesting (movies, games, books, sports teams, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ee4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ ACTIVITY 1: Create Your Own DataFrame\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TODO: Create a DataFrame about something you're interested in!\n",
    "# Requirements:\n",
    "#   - At least 4 columns\n",
    "#   - At least 5 rows\n",
    "#   - Mix of numeric and text data\n",
    "\n",
    "# Example structure (replace with your own data!):\n",
    "my_data = pd.DataFrame({\n",
    "    'title': ['TODO: Add your data'],\n",
    "    'year': [2024],\n",
    "    'rating': [0.0],\n",
    "    'category': ['Example']\n",
    "})\n",
    "\n",
    "print(\"ğŸ“Š My Custom DataFrame:\")\n",
    "print(my_data)\n",
    "\n",
    "# TODO: Use head(), info(), and describe() on your DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de4e57",
   "metadata": {},
   "source": [
    "### ğŸ‹ï¸ Activity 2: Data Loading Challenge\n",
    "Write a safe CSV loading function that:\n",
    "1. Checks if the file exists\n",
    "2. Uses try/except for error handling  \n",
    "3. Prints a summary of the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ ACTIVITY 2: Create a Safe Data Loading Function\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TODO: Complete this function\n",
    "\n",
    "def my_safe_loader(filepath):\n",
    "    \"\"\"\n",
    "    Safely load a CSV file with error handling.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame if successful, None otherwise\n",
    "    \"\"\"\n",
    "    # TODO: Add file existence check\n",
    "    \n",
    "    # TODO: Add try/except block\n",
    "    \n",
    "    # TODO: Return the DataFrame or None\n",
    "    pass\n",
    "\n",
    "# Test your function:\n",
    "# result = my_safe_loader('sample_employees.csv')\n",
    "# if result is not None:\n",
    "#     print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783f928",
   "metadata": {},
   "source": [
    "### ğŸ‹ï¸ Activity 3: Data Profiling\n",
    "Use the techniques you learned to explore the sample employee data:\n",
    "1. How many employees are there?\n",
    "2. What's the average salary?\n",
    "3. Which columns have missing data (if any)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3208bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ ACTIVITY 3: Explore the Employee Data\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Load the sample data\n",
    "emp_df = pd.read_csv('sample_employees.csv')\n",
    "\n",
    "# TODO: Answer these questions using pandas methods:\n",
    "\n",
    "# 1. How many employees are there?\n",
    "num_employees = None  # Use len() or .shape\n",
    "\n",
    "# 2. What's the average salary?\n",
    "avg_salary = None  # Use .mean()\n",
    "\n",
    "# 3. What's the highest salary?\n",
    "max_salary = None  # Use .max()\n",
    "\n",
    "# 4. List all unique cities\n",
    "cities = None  # Use .unique()\n",
    "\n",
    "# Print your answers:\n",
    "print(\"ğŸ“Š Employee Data Analysis\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total employees: {num_employees}\")\n",
    "print(f\"Average salary: ${avg_salary}\")\n",
    "print(f\"Highest salary: ${max_salary}\")\n",
    "print(f\"Cities: {cities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f20fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Section 7: Key Takeaways & Summary\n",
    "\n",
    "### ğŸ¯ What You Learned Today\n",
    "\n",
    "| Concept | Key Points |\n",
    "|---------|------------|\n",
    "| **Pandas** | The essential library for data manipulation in Python |\n",
    "| **Series** | 1D labeled array - like a column of data |\n",
    "| **DataFrame** | 2D labeled table - like a spreadsheet |\n",
    "| **Loading Data** | `pd.read_csv()` with error handling |\n",
    "| **Inspection** | `head()`, `info()`, `describe()`, `shape` |\n",
    "\n",
    "### ğŸ’¡ Best Practices Checklist\n",
    "\n",
    "âœ… Always import pandas with `import pandas as pd`  \n",
    "âœ… Use descriptive variable names for DataFrames  \n",
    "âœ… Handle errors when loading files  \n",
    "âœ… Inspect data before analysis with `info()` and `describe()`  \n",
    "âœ… Check for missing values with `isnull().sum()`  \n",
    "\n",
    "### ğŸ”® What's Next?\n",
    "\n",
    "In the next session, we'll practice these concepts together in group activities and learn about:\n",
    "- More advanced DataFrame operations\n",
    "- Selecting and filtering data\n",
    "- Working with real-world datasets\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ† Great job completing Week 4 Session 1!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe24216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ§¹ CLEANUP: Remove temporary files created during this session\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import os\n",
    "\n",
    "# Remove the sample CSV we created\n",
    "if os.path.exists('sample_employees.csv'):\n",
    "    os.remove('sample_employees.csv')\n",
    "    print(\"âœ… Cleaned up: sample_employees.csv removed\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ No cleanup needed\")\n",
    "    \n",
    "print(\"\\nğŸ‰ Session complete! See you in the group session!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
